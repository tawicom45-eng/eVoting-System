# Intermediate Data Engineering Projects

Advanced data engineering projects building on beginner fundamentals:

1. **01_Data_Warehouse** — Multi-table schema design, fact/dimension tables, slowly changing dimensions
2. **02_Airflow_ETL_Pipeline** — Workflow orchestration with Apache Airflow, DAGs, task dependencies
3. **03_API_Data_Integration** — Real-time API consumption, pagination, error handling, data normalization
4. **04_IoT_Sensor_Data_Collection** — Time-series data, high-frequency ingestion, aggregation, real-time processing
5. **05_Twitter_Reddit_Data_Pipeline** — Social media API integration, NLP-ready data preprocessing, sentiment analysis pipeline

Each project includes:
- Advanced ETL patterns and best practices
- Production-grade error handling and logging
- Comprehensive test suites
- Performance benchmarking
- Documentation with examples

## Quick Start

```bash
cd Intermediate/01_Data_Warehouse
python code/etl_warehouse.py --help
```

All projects process 100k+ rows of data and demonstrate scalable patterns.
